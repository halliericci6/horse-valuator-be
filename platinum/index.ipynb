{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pulls data from platinumequineauction.com. This data includes Contact info, location, breed, foal date, sex, color, height, markings, and registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumPages(url):\n",
    "    getReq=requests.get(url)\n",
    "    soup = BeautifulSoup(getReq.content, 'html.parser')\n",
    "    pages=soup.find_all('a', class_='page-numbers')\n",
    "    pagesText=[a.get_text(strip=True) for a in pages]\n",
    "    return int(pagesText[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getColumns(url):\n",
    "    getReq=requests.get(url)\n",
    "    soup = BeautifulSoup(getReq.content, 'html.parser')\n",
    "    tableAttributes=soup.find_all('th',class_='woocommerce-product-attributes-item__label')\n",
    "    tableAttributesTexts=[th.get_text(strip=True) for th in tableAttributes]\n",
    "    return tableAttributesTexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineLocality(dic):\n",
    "    nearby_states=['NJ','NY', 'PA', 'DE', 'CT'] \n",
    "    #have a dictionary\n",
    "    \n",
    "    if 'Location' in dic and dic['Location']:\n",
    "        location=dic['Location']\n",
    "        try:\n",
    "            state = location.split(\",\")[1].strip()\n",
    "            return state in nearby_states\n",
    "        except IndexError:\n",
    "            # Handle the case where location does not have a comma or is malformed\n",
    "            print(f\"Warning: Unable to extract state from location '{location}'\")\n",
    "            print(dic)\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapePage(pageNo):\n",
    "    url=f\"https://platinumequineauction.com/expired-auctions/page/{pageNo}\"\n",
    "    r=requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    #extract the attributes, values, prices, link to more information\n",
    "    tableAttributes=soup.find_all('th',class_='woocommerce-product-attributes-item__label')\n",
    "    tableValues=soup.find_all('td',class_='woocommerce-product-attributes-item__value')\n",
    "    biddingValue=soup.find_all('span', class_='price')\n",
    "    listingUrls=soup.find_all('a', class_='woocommerce-LoopProduct-link woocommerce-loop-product__link')\n",
    "    hrefs = [link['href'] for link in listingUrls if link.has_attr('href')]\n",
    "\n",
    "    #parse text\n",
    "    tableValuesTexts = [td.find(\"p\").get_text(strip=True) for td in tableValues]\n",
    "    tableAttributesTexts=[th.get_text(strip=True) for th in tableAttributes]\n",
    "    biddingValueTexts=[span.get_text(strip=True) for span in biddingValue]\n",
    "\n",
    " \n",
    "\n",
    "    #build results list for this page\n",
    "    num_keys=9\n",
    "    pageResults=[]\n",
    "    for i in range(0, len(tableValuesTexts), num_keys):\n",
    "        # Create the dictionary from list1 and list2\n",
    "        #0, 9, 18\n",
    "        #count by the number of keys \n",
    "        \n",
    "        dictionary = dict(zip([key.capitalize() for key in tableAttributesTexts[i:i + num_keys]], tableValuesTexts[i:i + num_keys]))\n",
    "        # Add the \"Price\" key with the value from biddingValueTexts\n",
    "        dictionary[\"Price\"] = biddingValueTexts[i // num_keys]\n",
    "        dictionary[\"Url\"]=hrefs[i//num_keys]\n",
    "        dictionary[\"Page\"]=pageNo\n",
    "        dictionary[\"Is_Local\"]=determineLocality(dictionary)\n",
    "        pageResults.append(dictionary)\n",
    "    return pageResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl=\"https://platinumequineauction.com/expired-auctions\"\n",
    "numPages=getNumPages(baseUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1 of 153...\n",
      "20\n",
      "Scraping page 2 of 153...\n",
      "20\n",
      "Scraping page 3 of 153...\n",
      "20\n",
      "Scraping page 4 of 153...\n",
      "20\n",
      "Scraping page 5 of 153...\n",
      "20\n",
      "Scraping page 6 of 153...\n",
      "20\n",
      "Scraping page 7 of 153...\n",
      "20\n",
      "Scraping page 8 of 153...\n",
      "20\n",
      "Scraping page 9 of 153...\n",
      "20\n",
      "Scraping page 10 of 153...\n",
      "20\n",
      "Scraping page 11 of 153...\n",
      "20\n",
      "Scraping page 12 of 153...\n",
      "20\n",
      "Scraping page 13 of 153...\n",
      "20\n",
      "Scraping page 14 of 153...\n",
      "20\n",
      "Scraping page 15 of 153...\n",
      "20\n",
      "Scraping page 16 of 153...\n",
      "20\n",
      "Scraping page 17 of 153...\n",
      "20\n",
      "Scraping page 18 of 153...\n",
      "20\n",
      "Scraping page 19 of 153...\n",
      "20\n",
      "Scraping page 20 of 153...\n",
      "20\n",
      "Scraping page 21 of 153...\n",
      "20\n",
      "Scraping page 22 of 153...\n",
      "20\n",
      "Scraping page 23 of 153...\n",
      "20\n",
      "Scraping page 24 of 153...\n",
      "20\n",
      "Scraping page 25 of 153...\n",
      "20\n",
      "Scraping page 26 of 153...\n",
      "20\n",
      "Scraping page 27 of 153...\n",
      "20\n",
      "Scraping page 28 of 153...\n",
      "20\n",
      "Scraping page 29 of 153...\n",
      "20\n",
      "Scraping page 30 of 153...\n",
      "20\n",
      "Scraping page 31 of 153...\n",
      "20\n",
      "Scraping page 32 of 153...\n",
      "20\n",
      "Scraping page 33 of 153...\n",
      "20\n",
      "Scraping page 34 of 153...\n",
      "20\n",
      "Scraping page 35 of 153...\n",
      "20\n",
      "Scraping page 36 of 153...\n",
      "20\n",
      "Scraping page 37 of 153...\n",
      "20\n",
      "Scraping page 38 of 153...\n",
      "20\n",
      "Scraping page 39 of 153...\n",
      "20\n",
      "Scraping page 40 of 153...\n",
      "20\n",
      "Scraping page 41 of 153...\n",
      "20\n",
      "Scraping page 42 of 153...\n",
      "20\n",
      "Scraping page 43 of 153...\n",
      "20\n",
      "Scraping page 44 of 153...\n",
      "20\n",
      "Scraping page 45 of 153...\n",
      "20\n",
      "Scraping page 46 of 153...\n",
      "20\n",
      "Scraping page 47 of 153...\n",
      "20\n",
      "Scraping page 48 of 153...\n",
      "20\n",
      "Scraping page 49 of 153...\n",
      "20\n",
      "Scraping page 50 of 153...\n",
      "20\n",
      "Scraping page 51 of 153...\n",
      "20\n",
      "Scraping page 52 of 153...\n",
      "20\n",
      "Scraping page 53 of 153...\n",
      "20\n",
      "Scraping page 54 of 153...\n",
      "20\n",
      "Scraping page 55 of 153...\n",
      "20\n",
      "Scraping page 56 of 153...\n",
      "20\n",
      "Scraping page 57 of 153...\n",
      "20\n",
      "Scraping page 58 of 153...\n",
      "20\n",
      "Scraping page 59 of 153...\n",
      "20\n",
      "Scraping page 60 of 153...\n",
      "20\n",
      "Scraping page 61 of 153...\n",
      "20\n",
      "Scraping page 62 of 153...\n",
      "20\n",
      "Scraping page 63 of 153...\n",
      "20\n",
      "Scraping page 64 of 153...\n",
      "20\n",
      "Scraping page 65 of 153...\n",
      "20\n",
      "Scraping page 66 of 153...\n",
      "20\n",
      "Scraping page 67 of 153...\n",
      "20\n",
      "Scraping page 68 of 153...\n",
      "20\n",
      "Scraping page 69 of 153...\n",
      "20\n",
      "Scraping page 70 of 153...\n",
      "20\n",
      "Scraping page 71 of 153...\n",
      "20\n",
      "Scraping page 72 of 153...\n",
      "20\n",
      "Scraping page 73 of 153...\n",
      "20\n",
      "Scraping page 74 of 153...\n",
      "20\n",
      "Scraping page 75 of 153...\n",
      "20\n",
      "Scraping page 76 of 153...\n",
      "20\n",
      "Scraping page 77 of 153...\n",
      "20\n",
      "Scraping page 78 of 153...\n",
      "20\n",
      "Scraping page 79 of 153...\n",
      "20\n",
      "Warning: Unable to extract state from location 'Missouri'\n",
      "{'Contact': 'Joe Vitale314-422-3347', 'Location': 'Missouri', 'Breed': 'Quarter Horse', 'Foal date': '2014', 'Sex': 'Gelding', 'Color': 'Black', 'Height': '14.2', 'Markings': 'Blaze, 3 stockings', 'Registered': 'No', 'Price': 'Winning Bid:$6,500.00', 'Url': 'https://platinumequineauction.com/product/boo-2/', 'Page': 79}\n",
      "Scraping page 80 of 153...\n",
      "20\n",
      "Scraping page 81 of 153...\n",
      "20\n",
      "Scraping page 82 of 153...\n",
      "20\n",
      "Scraping page 83 of 153...\n",
      "20\n",
      "Scraping page 84 of 153...\n",
      "20\n",
      "Scraping page 85 of 153...\n",
      "20\n",
      "Scraping page 86 of 153...\n",
      "20\n",
      "Scraping page 87 of 153...\n",
      "20\n",
      "Scraping page 88 of 153...\n",
      "20\n",
      "Scraping page 89 of 153...\n",
      "20\n",
      "Scraping page 90 of 153...\n",
      "20\n",
      "Scraping page 91 of 153...\n",
      "20\n",
      "Scraping page 92 of 153...\n",
      "20\n",
      "Scraping page 93 of 153...\n",
      "20\n",
      "Scraping page 94 of 153...\n",
      "20\n",
      "Scraping page 95 of 153...\n",
      "20\n",
      "Scraping page 96 of 153...\n",
      "20\n",
      "Scraping page 97 of 153...\n",
      "20\n",
      "Scraping page 98 of 153...\n",
      "20\n",
      "Scraping page 99 of 153...\n",
      "20\n",
      "Scraping page 100 of 153...\n",
      "20\n",
      "Scraping page 101 of 153...\n",
      "20\n",
      "Scraping page 102 of 153...\n",
      "20\n",
      "Scraping page 103 of 153...\n",
      "20\n",
      "Scraping page 104 of 153...\n",
      "20\n",
      "Scraping page 105 of 153...\n",
      "20\n",
      "Scraping page 106 of 153...\n",
      "20\n",
      "Scraping page 107 of 153...\n",
      "20\n",
      "Scraping page 108 of 153...\n",
      "20\n",
      "Scraping page 109 of 153...\n",
      "20\n",
      "Scraping page 110 of 153...\n",
      "20\n",
      "Scraping page 111 of 153...\n",
      "20\n",
      "Scraping page 112 of 153...\n",
      "20\n",
      "Scraping page 113 of 153...\n",
      "20\n",
      "Scraping page 114 of 153...\n",
      "20\n",
      "Scraping page 115 of 153...\n",
      "20\n",
      "Scraping page 116 of 153...\n",
      "20\n",
      "Scraping page 117 of 153...\n",
      "20\n",
      "Scraping page 118 of 153...\n",
      "20\n",
      "Scraping page 119 of 153...\n",
      "20\n",
      "Scraping page 120 of 153...\n",
      "20\n",
      "Scraping page 121 of 153...\n",
      "20\n",
      "Scraping page 122 of 153...\n",
      "20\n",
      "Scraping page 123 of 153...\n",
      "20\n",
      "Scraping page 124 of 153...\n",
      "20\n",
      "Scraping page 125 of 153...\n",
      "20\n",
      "Scraping page 126 of 153...\n",
      "20\n",
      "Scraping page 127 of 153...\n",
      "20\n",
      "Scraping page 128 of 153...\n",
      "20\n",
      "Scraping page 129 of 153...\n",
      "20\n",
      "Scraping page 130 of 153...\n",
      "20\n",
      "Scraping page 131 of 153...\n",
      "20\n",
      "Scraping page 132 of 153...\n",
      "20\n",
      "Scraping page 133 of 153...\n",
      "20\n",
      "Scraping page 134 of 153...\n",
      "20\n",
      "Scraping page 135 of 153...\n",
      "20\n",
      "Scraping page 136 of 153...\n",
      "20\n",
      "Scraping page 137 of 153...\n",
      "20\n",
      "Scraping page 138 of 153...\n",
      "20\n",
      "Scraping page 139 of 153...\n",
      "20\n",
      "Scraping page 140 of 153...\n",
      "20\n",
      "Scraping page 141 of 153...\n",
      "20\n",
      "Scraping page 142 of 153...\n",
      "20\n",
      "Scraping page 143 of 153...\n",
      "20\n",
      "Scraping page 144 of 153...\n",
      "20\n",
      "Scraping page 145 of 153...\n",
      "20\n",
      "Scraping page 146 of 153...\n",
      "20\n",
      "Scraping page 147 of 153...\n",
      "20\n",
      "Scraping page 148 of 153...\n",
      "20\n",
      "Scraping page 149 of 153...\n",
      "20\n",
      "Scraping page 150 of 153...\n",
      "20\n",
      "Scraping page 151 of 153...\n",
      "20\n",
      "Scraping page 152 of 153...\n",
      "20\n",
      "Scraping page 153 of 153...\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "allResults=[]\n",
    "for pageNo in range(1, numPages+1):\n",
    "    print(f\"Scraping page {pageNo} of {numPages}...\")\n",
    "    time.sleep(1)\n",
    "    scrapedPage=scrapePage(pageNo)\n",
    "    for d in scrapedPage:\n",
    "        allResults.append(d)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(allResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contact</th>\n",
       "      <th>Location</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Registered</th>\n",
       "      <th>Foal date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Color</th>\n",
       "      <th>Height</th>\n",
       "      <th>Markings</th>\n",
       "      <th>Price</th>\n",
       "      <th>Url</th>\n",
       "      <th>Page</th>\n",
       "      <th>Is_Local</th>\n",
       "      <th>Name</th>\n",
       "      <th>Consignor</th>\n",
       "      <th>For more info call</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellesse Schwartz248-390-6831</td>\n",
       "      <td>Howell, MI</td>\n",
       "      <td>Miniature Horse</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2017</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>Chestnut</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4 Stockings</td>\n",
       "      <td>Reserve price Not met!</td>\n",
       "      <td>https://platinumequineauction.com/product/aloh...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Longhorn RanchDina 831-537-1915</td>\n",
       "      <td>Afton, WY</td>\n",
       "      <td>Quarter Horse</td>\n",
       "      <td>No</td>\n",
       "      <td>2017</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>Palomino</td>\n",
       "      <td>13.3</td>\n",
       "      <td>None</td>\n",
       "      <td>Winning Bid:$7,250.00</td>\n",
       "      <td>https://platinumequineauction.com/product/herb...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maxwell Quality HorsesLandon 704-689-9035</td>\n",
       "      <td>Cherryville, NC</td>\n",
       "      <td>Quarter Horse</td>\n",
       "      <td>No</td>\n",
       "      <td>2018</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>Bay</td>\n",
       "      <td>15.1</td>\n",
       "      <td>4 Socks</td>\n",
       "      <td>Winning Bid:$4,450.00</td>\n",
       "      <td>https://platinumequineauction.com/product/ty/</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buster HorsesAshley 214-605-7174</td>\n",
       "      <td>Weatherford, TX</td>\n",
       "      <td>Friesian Sport Horse</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2018</td>\n",
       "      <td>Gelding</td>\n",
       "      <td>Black</td>\n",
       "      <td>15.2</td>\n",
       "      <td>None</td>\n",
       "      <td>Winning Bid:$10,450.00</td>\n",
       "      <td>https://platinumequineauction.com/product/coun...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent Barnett662-927-0796</td>\n",
       "      <td>Calhoun City, MS</td>\n",
       "      <td>Quarter Horse</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2020</td>\n",
       "      <td>Mare</td>\n",
       "      <td>Bay</td>\n",
       "      <td>14.3</td>\n",
       "      <td>Blaze</td>\n",
       "      <td>Winning Bid:$7,000.00</td>\n",
       "      <td>https://platinumequineauction.com/product/swee...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Contact          Location  \\\n",
       "0               Ellesse Schwartz248-390-6831        Howell, MI   \n",
       "1            Longhorn RanchDina 831-537-1915         Afton, WY   \n",
       "2  Maxwell Quality HorsesLandon 704-689-9035   Cherryville, NC   \n",
       "3           Buster HorsesAshley 214-605-7174   Weatherford, TX   \n",
       "4                  Trent Barnett662-927-0796  Calhoun City, MS   \n",
       "\n",
       "                  Breed Registered Foal date      Sex     Color Height  \\\n",
       "0       Miniature Horse        Yes      2017  Gelding  Chestnut    9.2   \n",
       "1         Quarter Horse         No      2017  Gelding  Palomino   13.3   \n",
       "2         Quarter Horse         No      2018  Gelding       Bay   15.1   \n",
       "3  Friesian Sport Horse        Yes      2018  Gelding     Black   15.2   \n",
       "4         Quarter Horse        Yes      2020     Mare       Bay   14.3   \n",
       "\n",
       "      Markings                   Price  \\\n",
       "0  4 Stockings  Reserve price Not met!   \n",
       "1         None   Winning Bid:$7,250.00   \n",
       "2      4 Socks   Winning Bid:$4,450.00   \n",
       "3         None  Winning Bid:$10,450.00   \n",
       "4        Blaze   Winning Bid:$7,000.00   \n",
       "\n",
       "                                                 Url  Page  Is_Local Name  \\\n",
       "0  https://platinumequineauction.com/product/aloh...     1     False  NaN   \n",
       "1  https://platinumequineauction.com/product/herb...     1     False  NaN   \n",
       "2      https://platinumequineauction.com/product/ty/     1     False  NaN   \n",
       "3  https://platinumequineauction.com/product/coun...     1     False  NaN   \n",
       "4  https://platinumequineauction.com/product/swee...     1     False  NaN   \n",
       "\n",
       "  Consignor For more info call  \n",
       "0       NaN                NaN  \n",
       "1       NaN                NaN  \n",
       "2       NaN                NaN  \n",
       "3       NaN                NaN  \n",
       "4       NaN                NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_metrics_overall(df, breed=None, local=None, registered=None ):\n",
    "    df['Price'] = df['Price'].astype(str)\n",
    "    #extract numerical value of the price\n",
    "    df['Price'] = df['Price'].str.extract(r'(\\d[\\d,\\.]*)')[0]\n",
    "    df['Price'] = df['Price'].replace({',': ''}, regex=True).astype(float)\n",
    "    df['Registered'] = df['Registered'].fillna('')  # cSpell:ignore fillna\n",
    "    df['Breed']=df['Breed'].fillna('')\n",
    "    df['Registered'] = df['Registered'].astype(str)\n",
    "    df['Breed'] = df['Breed'].astype(str)\n",
    "    if breed is not None:\n",
    "        df=df[df['Breed'].str.contains(breed, case=False, na=False)]\n",
    "    if local is not None:\n",
    "        df = df[df['Is_Local'] == local]\n",
    "    if registered is not None:\n",
    "        df=df[df['Registered'].str.contains(registered, case=False, na=False)]\n",
    "    mean_price = df['Price'].mean()\n",
    "    median_price = df['Price'].median()\n",
    "    min_price = df['Price'].min()\n",
    "\n",
    "    print(f\"Mean Price: ${mean_price:.2f}\")\n",
    "    print(f\"Median Price: ${median_price:.2f}\")\n",
    "    print(f\"Minimum Price: ${min_price:.2f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Price: $7667.21\n",
      "Median Price: $6675.00\n",
      "Minimum Price: $3750.00\n"
     ]
    }
   ],
   "source": [
    "determine_metrics_overall(df, breed='Quarter', local=True, registered='No')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('platinum_auction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
